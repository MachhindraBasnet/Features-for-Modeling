{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Challenge: what model can answer this question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure all of these ideas are organized in your mind, please go through the list of problems below. For each, identify which supervised learning method(s) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Predict the running times of prospective Olympic sprinters using data from the last 20 Olympics.\n",
    " \n",
    "    K Nearest Neighbor Regression where we can predict the running times based on similar observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. You have more features (columns) than rows in your dataset.\n",
    "\n",
    "LASSO as  it penalizes the features only adding complexity but not explained variance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Identify the most important characteristic predicting likelihood of being jailed before age 20.\\\n",
    "\n",
    "Gradient Boost can be used to determine the features/charcateristics predicting likelihood of being jailed before age 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Implement a filter to “highlight” emails that might be important to the recipient\n",
    "\n",
    "Naive Bayes to classify  the emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. You have 1000+ features.\n",
    "\n",
    "LASSO Regression is the way to go. Also it depends on # of rows. If we have terabytes of data with ~1K features maybe logistic regression without regularization would still work as we can compensate the # of features with # of rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Predict whether someone who adds items to their cart on a website will purchase the items.\n",
    "\n",
    "Logistic Regression or Random forest. We can predict the prbability classify whether or not someone adds items to their cart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Your dataset dimensions are 982400 x 500\n",
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Identify faces in an image.\n",
    "\n",
    "KNN Classifier, based on similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Predict which of three flavors of ice cream will be most popular with boys vs girls.\n",
    "\n",
    "Random Forest Classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
